<!DOCTYPE html><html lang="en" dir="ltr"><head><meta charSet="utf-8" class="next-head next-head"/><title class="jsx-1947240685 jsx-1947240685 next-head">Understanding Hash-based Motion Estimation</title><meta name="description" content="An attempt to explain Hash-based Motion Estimation in VVC." class="jsx-1947240685 jsx-1947240685 next-head"/><link rel="preload" href="/_next/2a286705-6cc6-4a91-b673-12627c13bded/page/blog/understanding-hash-based-motion-estimation.js" as="script"/><link rel="preload" href="/_next/2a286705-6cc6-4a91-b673-12627c13bded/page/_error.js" as="script"/><link rel="preload" href="/_next/2a286705-6cc6-4a91-b673-12627c13bded/main.js" as="script"/><style id="jss-server-side"></style><style id="__jsx-1319436554">.jsx-1319436554{margin:15px 0;}</style><style id="__jsx-2400435237">span.jsx-2400435237{font-family:'SFMono-Regular',Consolas,'Liberation Mono',Menlo, Courier,monospace;padding:2px 5px;margin:0;font-size:80%;color:#c62828;background-color:#eeeeee;border-radius:2.5px;}</style><style id="__jsx-1371294351">.code.jsx-1371294351{margin:15px 0;}</style><style id="__jsx-138357423">.no_marginp.jsx-138357423{margin:0.5px 0 0 0;font-weight:400;}</style><style id="__jsx-2588419384">div.jsx-2588419384{background-color:#e1f5fe;padding:5px 5px 5px 5px;margin:1px 0;color:#01579b;border-radius:5px;}.widgets_div.jsx-2588419384{border-bottom:thin #edf1f2 solid;padding:0.5px 0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}.widgets_div.jsx-2588419384 .icon_div.jsx-2588419384{display:inline-block;font-size:15px;font-weight:500;}.text_div.jsx-2588419384{display:inline-block;margin:0.5px 0 0 0;padding:5px 5px 5px 0px;}</style><style id="__jsx-2207567817">.indentRow.jsx-2207567817{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><style id="__jsx-3736279659">.spanPaddingRight.jsx-1947240685{display:block;margin:0 auto 0 auto;max-width:650px;padding:0 21px;}.span.jsx-1947240685{padding-left:30px;}.backIcon.jsx-1947240685{padding-right:6px;}a.jsx-1947240685{color:#fff;-webkit-text-decoration:none;text-decoration:none;opacity:1;}a.jsx-1947240685:hover{color:#fefefe;-webkit-text-decoration:none;text-decoration:none;opacity:0.6;}.footerWrapper.jsx-1947240685{margin-top:72px;background:#f2f2f2;height:120px;z-index:1100;font-size:12px;color:gray;}.copyright.jsx-1947240685{-webkit-flex:1;-ms-flex:1;flex:1;padding-top:36px;text-align:center;}.headerTop.jsx-1947240685{padding-top:13px;padding-bottom:13px;background-color:#333;}.outerContainer.jsx-1947240685{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;background-color:#fafafa;width:100%;height:100%;}.innerContainer.jsx-1947240685{padding:0 21px;-webkit-flex:1;-ms-flex:1;flex:1;}.content.jsx-1947240685{margin:0 auto 0 auto;max-width:650px;padding-top:24px;}.content.jsx-1947240685 h1.jsx-1947240685{font-size:1.5rem;font-weight:500;font-family:Roboto,Helvetica,Arial,sans-serif;line-height:1.15417em;color:rgba(0,0,0,0.54);}.date.jsx-1947240685{color:#888;font-size:12px;padding-top:3px;}.markdown-content.jsx-1947240685{margin:50px 0 0 0;}</style><style id="__jsx-759730511">.markdown-content{color:rgba(0,0,0,0.87);line-height:1.46429em;font-size:0.9rem;font-weight:400;}.markdown-content hr{border:0;border-bottom:1px solid #8bc34a;margin:40px 60px;}.markdown-content a{color:#1e88e5;-webkit-text-decoration:none;text-decoration:none;border-bottom:1px solid #1e88e5;}.markdown-content strong{font-weight:500;}.markdown-content li{margin:10px 0;}.markdown-content h2{font-size:1.2rem;font-weight:500;font-family:Roboto,Helvetica,Arial,sans-serif;line-height:1.15417em;color:rgba(0,0,0,0.87);}.markdown-content h3{font-size:0.9rem;font-weight:500;font-family:Roboto,Helvetica,Arial,sans-serif;line-height:1.10417em;text-transform:uppercase;color:rgba(0,0,0,0.87);}.markdown-content h4{font-size:0.9rem;font-weight:500;font-family:Roboto,Helvetica,Arial,sans-serif;line-height:1.10417em;color:rgba(0,0,0,0.87);}.markdown-content blockquote{padding:1px 0 1px 10px;margin:0;border-left:5px solid #8bc34a;}</style><style id="__jsx-1580160015"></style><style id="__jsx-3994937953">body{font-family:Roboto,-apple-system,BlinkMacSystemFont,'Segoe UI', Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji', 'Segoe UI Symbol';padding:0;margin:0;-webkit-font-smoothing:antialiased;}</style><title>Pharrell&#x27;s Website</title><link href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" rel="stylesheet"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"/><meta charSet="utf-8"/><meta name="viewport" content="user-scalable=0, initial-scale=1, minimum-scale=1, width=device-width, height=device-height"/><meta name="theme-color" content="#333"/><link rel="favicon.ico" sizes="512x512" href="/static/favicons/favicon.ico"/><link rel="apple-touch-icon" sizes="72x72" href="/static/favicons/icon-72x72.png"/><link rel="apple-touch-icon" sizes="120x120" href="/static/favicons/icon-120x120.png"/><link rel="apple-touch-icon" sizes="144x144" href="/static/favicons/icon-144x144.png"/><link rel="apple-touch-icon" sizes="152x152" href="/static/favicons/icon-152x152.png"/><link rel="apple-touch-icon" sizes="167x167" href="/static/favicons/icon-167x167.png"/><link rel="apple-touch-icon" sizes="180x180" href="/static/favicons/icon-180x180.png"/><link rel="apple-touch-icon" sizes="192x192" href="/static/favicons/icon-192x192.png"/><link rel="apple-touch-icon" sizes="384x384" href="/static/favicons/icon-384x384.png"/><link rel="apple-touch-icon" sizes="512x512" href="/static/favicons/icon-512x512.png"/><link rel="icon" type="image/png" href="/static/favicons/favicon.ico" sizes="512x512"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500"/><link href="https://fonts.googleapis.com/css?family=Kalam" rel="stylesheet"/><script src="/static/js/gitalk.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async=""></script></head><body><div id="__next"><div class="jsx-4078088743 jsx-4078088743" data-reactroot=""><article class="jsx-4078088743 jsx-4078088743"><main class="jsx-1947240685 jsx-1947240685 outerContainer"><div class="jsx-1947240685 jsx-1947240685 headerTop"><span class="jsx-1947240685 jsx-1947240685 spanPaddingRight"><a class="jsx-1947240685 jsx-1947240685" href="/blog/">&lt; Back</a></span></div><div class="jsx-1947240685 jsx-1947240685 innerContainer"><div class="jsx-1947240685 jsx-1947240685 content"><div class="jsx-1947240685 jsx-1947240685 date">Published on <!-- -->July 10, 2019</div><div class="jsx-1947240685 jsx-1947240685 date"></div><h1 class="jsx-1947240685 jsx-1947240685">Understanding Hash-based Motion Estimation</h1><div class="jsx-1947240685 jsx-1947240685 markdown-content"><div class="jsx-138357423 _markdown_"><div class="jsx-1319436554 jsx-1319436554">The post attempts to explain Hash-based Motion Estimation (HBME). It has been applied in SCC extention of HEVC thus not new. However, HBME is yet another additional coding tool when simply compare VVC and HEVC (if we are not talking about HEVC extension).</div><h2>Motivation</h2><div class="jsx-1319436554 jsx-1319436554">During the development of HEVC SCC, it is believed that hash-based motion search can overcome some shortcomings of conventional motion estimation [1].</div><ol><li><strong>Find blocks that match better</strong>: search range of HBME can be full picture instead of a local region. For screen contents, conventional motion search may not work well due to the limited search range. It can provide better long range motion compensation, thus complemental to conventional motion search.</li><li><strong>Expedite ME progress</strong>: in HBME, once a match will be found, the following checks can be early terminated.</li></ol><h2>Hash-based Motion Search</h2><div class="jsx-1319436554 jsx-1319436554">HBME is only allowed in NEXT profile [1] (Review of profile is available in last section). HBME is applicable to 4x4, 4x8, 8x4, 8x8, 16x16, 32x32 and 64x64 blocks. For inter coding, the HBME is performed before all coding modes. For each reference picture, several hash tables are generated. Each hash table corresponds to a specific block size that is allowed.</div><h3>Hash Table Generation</h3><blockquote><div class="jsx-1319436554 jsx-1319436554">When generating the hash values for different blocks, the CRC (Cyclic Redundancy Check) is used. To understand CRC, please refer to <a href="https://github.com/PharrellWANG/crc">crc</a> repository, in which different CRC algorithm implementations are provided in C++. The code in VTM4.0 for CRC algorithm has been extracted as a lib called <span class="jsx-2400435237 jsx-2400435237">CrcXVTM4</span>.</div></blockquote><div class="jsx-1319436554 jsx-1319436554">To save computation and achieve acceleration, the hash table generation is built as follows [1]:</div><ul><li>For 2x2 block, the block hash value is calculated directly from the original pixels (for YUV 4:2:0, only luma component is utilized). The CRC (Cyclic Redundancy Check) value is used as the hash value.</li><li>For 4x4, 8x8, 16x16, 32x32 and 64x64 square blocks, the hash value of the current block is the CRC value calculated from the CRC values of its four sub blocks.</li><li>For 4x8 and 8x4 blocks, the hash value of the current block is the CRC value calculated from the CRC values of its two sub 4x4 blocks.</li></ul><div class="jsx-1319436554 jsx-1319436554">To avoid the hash conflicts, the structure of inverted index table has been utilized. For example, see the code block below, if a generated <span class="jsx-2400435237 jsx-2400435237">hashValue</span> key causes duplication, the new <span class="jsx-2400435237 jsx-2400435237">BlockHash</span> object corresponding to that key will be pushed back to the vector of <span class="jsx-2400435237 jsx-2400435237">BlockHash</span> objects instead of simply overwrite the old object. The key design is the usage of that <span class="jsx-2400435237 jsx-2400435237">BlockHash</span> vector. When retrieving the <span class="jsx-2400435237 jsx-2400435237">BlockHash</span> object, if a <span class="jsx-2400435237 jsx-2400435237">hashValue</span> key points to a vector of size larger than 1, the correct <span class="jsx-2400435237 jsx-2400435237">BlockHash</span> object can still be located using the <span class="jsx-2400435237 jsx-2400435237">x</span> and <span class="jsx-2400435237 jsx-2400435237">y</span> coordinates.</div><div class="jsx-1319436554 jsx-1319436554"><div class="jsx-1371294351 jsx-1371294351 code"><pre style="display:block;background:white;padding:8px;color:#333333;overflow-x:auto;padding-bottom:20px;font-size:100%;border-radius:5px;background-color:#eeeeee;line-height:1.1"><code><span style="color:#a71d5d">void</span> TComHash::addToTable(<span style="color:#a71d5d">uint32_t</span> hashValue, <span style="color:#a71d5d">const</span> BlockHash&amp; blockHash)
{
  <span style="color:#a71d5d">if</span> (m_lookupTable[hashValue] == <span style="color:#0086b3">NULL</span>)
  {
    m_lookupTable[hashValue] = <span style="color:#a71d5d">new</span> <span>std</span>::<span>vector</span>&lt;BlockHash&gt;;
    m_lookupTable[hashValue]-&gt;push_back(blockHash);
  }
  <span style="color:#a71d5d">else</span>
  {
    m_lookupTable[hashValue]-&gt;push_back(blockHash);
  }
}

<span><span style="color:#a71d5d">struct</span> <span style="color:#795da3">BlockHash</span>
{</span>
  <span style="color:#a71d5d">short</span> x;
  <span style="color:#a71d5d">short</span> y;
  <span style="color:#a71d5d">uint32_t</span> hashValue2;
};</code></pre></div></div><div class="jsx-1319436554 jsx-1319436554">To control the length of hash table, some hash values will not be added into the table if their corresponding blocks satisfy the following conditions [1]:</div><ul><li>The pixels in each row (column) are identical.</li><li>The horizontal (vertical) position is not integral multiples of block width (height).</li></ul><h3>Early Termination</h3><div class="jsx-1319436554 jsx-1319436554">For inter coding, the hash-based motion search is performed before all coding modes. To accelerate the encoding process, the other coding modes (except the skip part of ETM_MERGE_SKIP, ETM_AFFINE, ETM_MERGE_TRIANGLE modes) and finer-grained block splitting are skipped if the following conditions are satisfied [1]:</div><ul><li>Current block size is 64x64.</li><li>Hash match is found in reference frame.</li><li>The QP of reference frame is not larger than that of current frame.</li></ul><div class="jsx-1319436554 jsx-1319436554">In addition, for all block sizes that hash search supports, the hash-based motion vector is checked for the start point initialization in the normal integral motion search. If the hash-based motion vector exists, the fractional motion estimation is skipped. In a recent implementation, for each sequence, it is determined if the proposed hash search is applied or not. By doing so, the encoding time for <em>camera captured</em> contents can be kept similar.</div><h2>Review</h2><h3>Profile, Level and Tier</h3><div class="jsx-1319436554 jsx-1319436554">In this section, the concepts of profile, level and tier in standards are reviewed.</div><div class="jsx-1319436554 jsx-1319436554">Some variation in capabilities of the standard is necessary to support a broad range of applications. This variation is handled by specifying profiles, levels and tiers.</div><div class="jsx-1319436554 jsx-1319436554">A <strong>profile</strong> defines the set of coding tools which may be used to encode a video sequence into a bitstream. The encoder is not required to use all coding tools available in the profile but may select the coding tools which it considers to be suitable [2]. A set of allowed profiles in VTM4.0 is shown below.</div><div class="jsx-1319436554 jsx-1319436554"><div class="jsx-1371294351 jsx-1371294351 code"><pre style="display:block;background:white;padding:8px;color:#333333;overflow-x:auto;padding-bottom:20px;font-size:100%;border-radius:5px;background-color:#eeeeee;line-height:1.1"><code><span style="color:#969896">// Profiles defined in VTM4.0</span>
<span style="color:#a71d5d">namespace</span> Profile{
  <span style="color:#a71d5d">enum</span> Name {
    NONE = <span>0</span>, MAIN = <span>1</span>, MAIN10 = <span>2</span>, MAINSTILLPICTURE = <span>3</span>,
    MAINREXT = <span>4</span>, HIGHTHROUGHPUTREXT = <span>5</span>, NEXT = <span>6</span> }; }</code></pre></div></div><div class="jsx-1319436554 jsx-1319436554">A <strong>level</strong> defines the degree of capability given a profile. Levels/degrees of capability are defined to establish the picture resolution, frame rate, bit rate, buffering capacity, and other aspects that are matters of degree rather than basic feature sets/coding tools.</div><div class="jsx-1319436554 jsx-1319436554"><div class="jsx-2588419384 jsx-2588419384"><div class="jsx-2588419384 jsx-2588419384 widgets_div"><div class="jsx-2588419384 jsx-2588419384 icon_div">Note: </div><div class="jsx-2588419384 jsx-2588419384 text_div"><div class="jsx-138357423 jsx-138357423"><p class="jsx-138357423 jsx-138357423 no_marginp">In HEVC, <ins class="jsx-138357423 jsx-138357423">Level 1</ins> only handles 176x144 resolution at 15 fps, whereas <ins class="jsx-138357423 jsx-138357423">level 4.1</ins> would be capable of 1920x1080 HDTV at 60 fps, and levels in version 1 are defined up to <ins class="jsx-138357423 jsx-138357423">level 6.1</ins>, which is capable of 8192x4320 video resolution at up to 120 fps. <br class="jsx-138357423 jsx-138357423"/></p></div></div></div></div></div><div class="jsx-1319436554 jsx-1319436554">In each level, <strong>tiers</strong> are defined based on the bit rates they are capable of handling. Main Tier is mainly used to meet the demand of consumer usage, while High Tier is used to provide adequate quality for professional usage than what would be necessary for consumer applications. Levels and tiers defined in VTM4.0 are shown below.</div><div class="jsx-1319436554 jsx-1319436554"><div class="jsx-1371294351 jsx-1371294351 code"><pre style="display:block;background:white;padding:8px;color:#333333;overflow-x:auto;padding-bottom:20px;font-size:100%;border-radius:5px;background-color:#eeeeee;line-height:1.1"><code><span style="color:#969896">// Tiers and Levels defined in VTM4.0</span>
<span style="color:#a71d5d">namespace</span> Level{
  <span style="color:#a71d5d">enum</span> Tier { MAIN = <span>0</span>, HIGH = <span>1</span>, };
  <span style="color:#a71d5d">enum</span> Name {
    NONE     = <span>0</span>,   LEVEL1   = <span>30</span>,  LEVEL2   = <span>60</span>,  LEVEL2_1 = <span>63</span>,  LEVEL3   = <span>90</span>,
    LEVEL3_1 = <span>93</span>,  LEVEL4   = <span>120</span>, LEVEL4_1 = <span>123</span>, LEVEL5   = <span>150</span>, LEVEL5_1 = <span>153</span>,
    LEVEL5_2 = <span>156</span>, LEVEL6   = <span>180</span>, LEVEL6_1 = <span>183</span>, LEVEL6_2 = <span>186</span>, LEVEL8_5 = <span>255</span>, }; }</code></pre></div></div><hr/><div class="jsx-1319436554 jsx-1319436554">References</div><div class="jsx-1319436554 jsx-1319436554"><div class="jsx-2207567817 jsx-2207567817 indentRow"><p class="jss1 jss10 jss18">[<!-- -->1<!-- -->]  </p><p class="jss1 jss10 jss18">J. Xu, J. Li, K. Zhang, L. Zhang, H. Liu, Y. Wang, P. Zhao, D. Hong, R. Xiong, &#x27;Non-CE8: Hash-based Motion Search&#x27;, Joint Video Exploration Team (JVET), docs. JVET-M0253, 2019.</p></div></div><div class="jsx-1319436554 jsx-1319436554"><div class="jsx-2207567817 jsx-2207567817 indentRow"><p class="jss1 jss10 jss18">[<!-- -->2<!-- -->]  </p><p class="jss1 jss10 jss18">V. Sze, M. Budagavi, and G. J. Sullivan (Editors), High Efficiency Video Coding (HEVC) Algorithms and Architectures (Integrated Circuits and Systems). Dordrecht: Springer, 2014.</p></div></div></div></div><button tabindex="0" class="jss40 jss25 jss30 jss35 jss29" type="button" aria-label="scroll-to-top" style="z-index:1800;position:fixed;bottom:24px;top:auto;right:16px;left:auto"><span class="jss26"><svg class="jss43" focusable="false" viewBox="0 0 24 24" aria-hidden="true"><g><path d="M4 12l1.41 1.41L11 7.83V20h2V7.83l5.58 5.59L20 12l-8-8-8 8z"></path></g></svg></span><span class="jss49"></span></button><div id="gitalk-container" class="jsx-1947240685 jsx-1947240685"></div></div></div><div class="jsx-1947240685 jsx-1947240685 footerWrapper"><div class="jsx-1947240685 jsx-1947240685 copyright">Copyright © 2018 - 2020 Pharrell</div></div></main></article></div></div><div id="__next-error"></div><script>
          __NEXT_DATA__ = {"props":{},"page":"/blog/understanding-hash-based-motion-estimation","pathname":"/blog/understanding-hash-based-motion-estimation","query":{},"buildId":"2a286705-6cc6-4a91-b673-12627c13bded","assetPrefix":"","nextExport":true,"err":null,"chunks":[]}
          module={}
          __NEXT_LOADED_PAGES__ = []
          __NEXT_LOADED_CHUNKS__ = []

          __NEXT_REGISTER_PAGE = function (route, fn) {
            __NEXT_LOADED_PAGES__.push({ route: route, fn: fn })
          }

          __NEXT_REGISTER_CHUNK = function (chunkName, fn) {
            __NEXT_LOADED_CHUNKS__.push({ chunkName: chunkName, fn: fn })
          }

          false
        </script><script async="" id="__NEXT_PAGE__/blog/understanding-hash-based-motion-estimation" src="/_next/2a286705-6cc6-4a91-b673-12627c13bded/page/blog/understanding-hash-based-motion-estimation.js"></script><script async="" id="__NEXT_PAGE__/_error" src="/_next/2a286705-6cc6-4a91-b673-12627c13bded/page/_error.js"></script><script src="/_next/2a286705-6cc6-4a91-b673-12627c13bded/main.js" async=""></script></body></html>